{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP28512 Laboratory Task2: Frequency-domain processing\n",
    "### Wenchang Liu 2019/02/17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1 Fourier series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "        \n",
    "F = 500\n",
    "Fs = 44100\n",
    "T = 1.0/Fs\n",
    "x = np.zeros(500)\n",
    "y = np.zeros(500)\n",
    "num_harmonics = 10\n",
    "for n in range(0, 500):\n",
    "    x[n] = n * T\n",
    "    y[n] = 0\n",
    "    for k in range(1, num_harmonics):\n",
    "        if k % 2 == 0:\n",
    "            # k is even\n",
    "            Bk = 0\n",
    "        else:\n",
    "            # k is odd\n",
    "            Bk = 1.0/k\n",
    "        y[n] = y[n] + Bk*np.sin(2*np.pi*k*F*n*T)    \n",
    "    \n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(x, y)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x\")\n",
    "axs.set_ylabel(\"y\")\n",
    "axs.set_title(\"Fourier series (a)\")\n",
    "\n",
    "F = 500\n",
    "Fs = 44100\n",
    "T = 1.0/Fs\n",
    "x = np.zeros(500)\n",
    "y = np.zeros(500)\n",
    "num_harmonics = 10\n",
    "for n in range(0, 500):\n",
    "    x[n] = n * T\n",
    "    y[n] = 0\n",
    "    for k in range(1, num_harmonics):\n",
    "        if k % 2 == 0:\n",
    "            # k is even\n",
    "            Ak = 0\n",
    "        else:\n",
    "            # k is odd\n",
    "            Ak = 1.0/(k*k)\n",
    "        y[n] = y[n] + Ak*np.cos(2*np.pi*k*F*n*T)    \n",
    "    \n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(x, y)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x\")\n",
    "axs.set_ylabel(\"y\")\n",
    "axs.set_title(\"Fourier series (b)\")\n",
    "\n",
    "F = 500\n",
    "Fs = 44100\n",
    "T = 1.0/Fs\n",
    "x = np.zeros(500)\n",
    "y = np.zeros(500)\n",
    "num_harmonics = 10\n",
    "for n in range(0, 500):\n",
    "    x[n] = n * T\n",
    "    y[n] = 0\n",
    "    for k in range(1, num_harmonics):\n",
    "        if k % 2 == 0:\n",
    "            # k is even\n",
    "            Bk = 0\n",
    "        else:\n",
    "            # k is odd\n",
    "            Bk = 1.0/k\n",
    "        if k == 3:\n",
    "            phase = np.pi/2\n",
    "        else:\n",
    "            phase = 0\n",
    "        y[n] = y[n] + Bk*np.sin(2*np.pi*k*F*n*T + phase)    \n",
    "    \n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(x, y)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x\")\n",
    "axs.set_ylabel(\"y\")\n",
    "axs.set_title(\"Fourier series (c)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 Q&A:\n",
    "1. Comment on the waveforms obtained for about 4 or more non-zero harmonics.\n",
    "   * They share the same fundamental frequency F, and all add up to simulate another waveform: (a) looks like a square wave, (b) looks like a triangle wave, (c) a different looking waveform(because of phase) \n",
    "2. What would you expect the waveforms to look like if you could take a very large number of harmonics?\n",
    "   * The result waveforms will be more smooth.\n",
    "3. In what ways are waveforms (a) and (c) similar and different?\n",
    "   * Similar: the wave formula is basically the same(except for phase)\n",
    "   * Different: waveforms (c) has a phase in one harmonic, but (a) does not.\n",
    "4. In what ways are waveforms (a) and (b) related to each other?\n",
    "   * They have the same period.\n",
    "5. Why might waveforms (a) and (c) sound similar over an analog telephone line?\n",
    "   * Because for telephone quality speech, ear is considered insensitve to phase, and for waveforms (a) and (c), the different shape of waveform is resulting from phase.\n",
    "6. If the waveform in (a) represented a sequence of pulses sent over an analog telephone line to represent a stream of bits, and the harmonics were affected by phase distortion to produce waveform (c), why might this cause a problem at the receiver?\n",
    "   * Because for bit stream, we may encode wave crest as 1 and wave trough as 0, though we our ears may insensitve to phase move, the bit stream is strictly encoded by the waveform, so since the waveform is different, the bit stream the receiver receive could also be different, and that may cause a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2 Frequency-domain processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio\n",
    "from numpy.fft import fft, ifft\n",
    "\n",
    "# read music from wavfile\n",
    "(Fs, music) = wavfile.read(\"noisySinewave.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "print(\"Sine wave with white noise:\")\n",
    "Audio(music, rate=Fs)\n",
    "\n",
    "# 500 samples plot\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(music[0: 500])\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x: time index\")\n",
    "axs.set_ylabel(\"y: voltage\")\n",
    "axs.set_title(\"Wavefrom plot for 500 samples segment\")\n",
    "\n",
    "# apply fft\n",
    "Fmusic = fft(music)\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(abs(Fmusic))\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"frequency index k\")\n",
    "axs.set_ylabel(\"magnitude\")\n",
    "axs.set_title(\"Apply fft to the whole sound file\")\n",
    "\n",
    "for i in range(0, len(Fmusic)):\n",
    "    if abs(Fmusic[i]) < 50000000:\n",
    "        Fmusic[i] = 0\n",
    "\n",
    "new_music = ifft(Fmusic)\n",
    "new_music = np.int16(new_music.real)\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(new_music[0:500])\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x: time index\")\n",
    "axs.set_ylabel(\"y: voltage\")\n",
    "axs.set_title(\"Waveform plot of 500 samples after frequency-domain processing\")\n",
    "\n",
    "print \"Sinewave sound after frequency-domain processing:\"\n",
    "Audio(new_music, rate=Fs)\n",
    "\n",
    "# for plot\n",
    "Fplot = fft(music[0:500])\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.stem(abs(Fplot[0:250])/250)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"frequency index k\")\n",
    "axs.set_ylabel(\"magnitude\")\n",
    "axs.set_title(\"Spectrum plot for 500 samples segment after fft(frequency index)\")\n",
    "\n",
    "x = np.arange(500)\n",
    "x = (x/500.0*Fs)\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.stem(x[0:250], abs(Fplot[0:250])/250)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"frequency/Hz\")\n",
    "axs.set_ylabel(\"magnitude\")\n",
    "axs.set_title(\"Spectrum plot for 500 samples segment after fft(frequency)\")\n",
    "\n",
    "for i in range(0, len(Fplot)):\n",
    "    if abs(Fplot[i]) < 5000*250:\n",
    "        Fplot[i] = 0\n",
    "        \n",
    "fig, axs = plt.subplots(1)\n",
    "axs.stem(abs(Fplot[0:250]))\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"frequency index k\")\n",
    "axs.set_ylabel(\"magnitude\")\n",
    "axs.set_title(\"Spectrum plot for 500 samples segment after set zeros\")\n",
    "        \n",
    "new_music = ifft(Fplot)\n",
    "new_music = np.int16(new_music.real)\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(new_music[0:500])\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x: time index\")\n",
    "axs.set_ylabel(\"y: voltage\")\n",
    "axs.set_title(\"Waveform plot for 500 samples segment after ifft\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 Q&A:\n",
    "1. If the original time-domain signal has N samples, how many frequency-domain samples do we obtain after performing  the FFT? Why do we only need to plot the first N/2 samples of the magnitude spectrum?\n",
    "   * N sampels.\n",
    "   * Because the waveform of the first N/2 and the next N/2 are symmetrical.\n",
    "2. How is periodic part of the sound and the noise seen in the magnitude spectrum?\n",
    "   * Each periodic part of waveform is seen as a stem bar in the magnitude spectrum, representing its magnitude at a specific frequency.\n",
    "3. How do you convert FFT frequency sample ('bin') number to frequency?\n",
    "   * Assume frequency index(number) to be x, them we can use frequency-index x (Fs/N) = x/500x44100 to get frequency(Hz)\n",
    "4. Would you describe the noise as being 'white'? Please explain your answer.\n",
    "   * Yes. Because white noise is the sound combined with all kinds of frequencies, and this \"noisySinewave\" has noises of a variety of frequencies.\n",
    "5. What value of threshold was chosen and why?\n",
    "   * For the 500 samples, threshold 5000x250=1250000 was chosen since we only want one sound with the largest magnitude left, so we may want this threshold to filter all other sounds.\n",
    "   * For the whole file, since we only want one sinewave sound left, I just simply set a high threshold 50,000,000 and make sure that only the sinewave is left.\n",
    "6. As you must apply the frequency-domain processing to the real and imaginary parts of the  FFT individually,  why would it be wrong to calculate thresholds for these parts individually rather than for the magnitude spectrum?\n",
    "   * Because only the magnitudes can represent the amplitudes in the time-domain.\n",
    "7. After applying the inverse FFT, is the resulting processed signal real, i.e. does it have zero imaginary part? If it were not real, what would you conclude from this?\n",
    "   * It has non-zero imaginary part, we can see that fft in python is not ideal, it might has some tiny errors(will not affect the audio much) in the calculation.\n",
    "8. Has any of the noise been removed by this ‘spectral subtraction’ process?\n",
    "   * Yes, we can see from both the graph of 500 samples and the audio produced by doing fft processing to the whole file, we can extract the sinewave behind the noises.\n",
    "9. What Fourier series components are present in the periodic part of the sound?\n",
    "   * The magnitude-frequency bars which are above the threshold is the periodic sinewave sound that we want to obtain.\n",
    "10. Did you have any chance of answering question 9 by just observing the time-domain waveform (i.e. if you had never heard of the FFT)?\n",
    "    * Yes, since the sine wave is periodic and the white noises are not periodic, so we can get the fourier series components by finding the periods in the time-domain, but it should be difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3 Transforming music files to & from frequency-domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "from scipy.fftpack import dct, idct\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio\n",
    "\n",
    "F = 100\n",
    "Fs = 44100\n",
    "T = 1.0/Fs # sampling period(seconds)\n",
    "A = 30000 # amplitude\n",
    "num_samples = 1024\n",
    "n = np.arange(0, num_samples)\n",
    "y = np.array([0]*num_samples, np.int16)\n",
    "y = np.int16(A*np.sin(2*np.pi*F*n*T)) # y=Asin(2pifnT)\n",
    "\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(n, y)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x\")\n",
    "axs.set_ylabel(\"y\")\n",
    "axs.set_title(\"Waveform of sinewave with 1024 samples\")\n",
    "\n",
    "# apply dctq\n",
    "y = dct(y, norm=\"ortho\")\n",
    "# y = idct(y, norm=\"ortho\")\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.stem(y)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x\")\n",
    "axs.set_ylabel(\"dct_y\")\n",
    "axs.set_title(\"dct plot for sinewave with 1024 samples\")\n",
    "\n",
    "# read wavefile\n",
    "(Fs, music) = wavfile.read(\"HQ-music44100-mono.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "print(\"Original HQ-music44100-mono.wav:\")\n",
    "Audio(music, rate=Fs)\n",
    "\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(music)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x: time index\")\n",
    "axs.set_ylabel(\"y: voltage\")\n",
    "axs.set_title(\"Original HQ-music waveform\")\n",
    "\n",
    "seg_count = 0\n",
    "step = 1024\n",
    "! rm \"HQ-music.bin\"\n",
    "with open (\"HQ-music.bin\", \"wb\") as f:\n",
    "    for i in range(0, len(music), step):\n",
    "        seg_count += 1\n",
    "        dctF = dct(music[i:i+step], norm=\"ortho\")\n",
    "        # scale dctF\n",
    "        SM = 400000\n",
    "        dctF = dctF/float(SM)    # Scale maximum to 1 (note the float)\n",
    "        dctF = dctF * 32767\n",
    "        dctF = np.int16(dctF)\n",
    "        np.save(f, dctF)\n",
    "    print \"number of segments: \", seg_count    \n",
    "with open (\"HQ-music.bin\", \"rb\") as f:\n",
    "    idctF = np.load(f)\n",
    "    music = np.int16(idct(idctF, norm=\"ortho\"))\n",
    "    for i in range(1, seg_count):\n",
    "        idctF = np.load(f)\n",
    "        music = np.append(music, np.int16(idct(idctF, norm=\"ortho\"))) \n",
    "        \n",
    "SM = max(abs(music))           # Get maximum amplitude\n",
    "music = music/float(SM)    # Scale maximum to 1 (note the float)\n",
    "music = np.int16(music * 32767)\n",
    "\n",
    "print(\"HQ-music44100-mono.wav after dct and inverse dct:\")\n",
    "Audio(music, rate=Fs)\n",
    "\n",
    "fig, axs = plt.subplots(1)\n",
    "axs.plot(music)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"x: time index\")\n",
    "axs.set_ylabel(\"y: voltage\")\n",
    "axs.set_title(\"HQ-music waveform after dct and inverse dct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3 Q&A:\n",
    "1. Why does the music have to be split up into sections when we wish to to apply frequency-domain processing?\n",
    "   * Because when transferring time-domain into frequency-domain, we cannot perserve the order of the occurances of all the fft/dct coefficients, so if the music we want to process is not stationary(very likely not stationary), we might get into trouble\n",
    "2. Does the transformation, saving to a file, reading back from the file and/or reconstruction introduce any noticeable distortion?\n",
    "   * No, there is almost no difference with the original HQ music.\n",
    "3. If there was some distortion, what would be the cause of it?\n",
    "   * Because we cast dct float results into int16, which may cause some errors, and when we use idct, these errors may cause slight distortion to our result music.\n",
    "   * And if we do not scale using the maximum of all the dct coefficients, we might get severe clicking sounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.4 Principles of mp3 encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "from scipy.fftpack import dct, idct\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio\n",
    "\n",
    "# read wavefile\n",
    "(Fs, music) = wavfile.read(\"HQ-music44100-mono.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "print(\"Original HQ-music44100-mono.wav:\")\n",
    "Audio(music, rate=Fs)\n",
    "\n",
    "\n",
    "def dct_proc(NB, threshold, music):\n",
    "    \n",
    "    seg_count = 0\n",
    "    non_zero_count = 0\n",
    "    zero_count = 0\n",
    "    cnt_16k = 0\n",
    "    step = 1024\n",
    "\n",
    "    with open (\"HQ-music.bin\", \"wb\") as f:\n",
    "        for i in range(0, len(music), step):\n",
    "            seg_count += 1\n",
    "            dctF = dct(music[i:i+step], norm=\"ortho\")\n",
    "            # set zeros\n",
    "            for j in range(0, len(dctF)):\n",
    "                if Fs/2.0/step*j > 16000:\n",
    "                    dctF[j] = 0\n",
    "                    cnt_16k += 1\n",
    "                    zero_count += 1\n",
    "                elif abs(dctF[j]) < threshold:\n",
    "                    dctF[j] = 0\n",
    "                    zero_count += 1\n",
    "                else:\n",
    "                    non_zero_count += 1\n",
    "            # scale dctF\n",
    "            SM = 400000          \n",
    "            dctF = dctF/float(SM)    # Scale maximum to 1 (note the float)\n",
    "            # number per bits = NB\n",
    "#             quant_dctF = np.round(dctF*(2**(NB-1)-0.5)-0.5)\n",
    "#             quant_dctF = np.int16(quant_dctF)\n",
    "#             dctF = np.int16((quant_dctF+0.5) * (2**(16-NB)))\n",
    "            quant_dctF = np.round(dctF*(2**(NB-1)-1))\n",
    "            quant_dctF = np.int16(quant_dctF)\n",
    "            dctF = np.int16(quant_dctF * (2**(16-NB)))\n",
    "            idctF = np.int16(dctF)\n",
    "            np.save(f, idctF)\n",
    "        print \"number of segments: \", seg_count\n",
    "\n",
    "#     fig, axs = plt.subplots(1)\n",
    "#     axs.stem(abs(idctF))\n",
    "#     axs.grid(True)\n",
    "#     axs.set_xlabel(\"x\")\n",
    "#     axs.set_ylabel(\"dct_y\")\n",
    "#     axs.set_title(\"dct plot for HQ-music\")\n",
    "\n",
    "    with open (\"HQ-music.bin\", \"rb\") as f:\n",
    "        idctF = np.load(f)\n",
    "        music = np.int16(idct(idctF, norm=\"ortho\"))\n",
    "        for i in range(1, seg_count):\n",
    "            idctF = np.load(f)\n",
    "            music = np.append(music, np.int16(idct(idctF, norm=\"ortho\"))) \n",
    "    SM = max(abs(music))\n",
    "    music = music/float(SM)\n",
    "    music = np.int16(music*32767)\n",
    "    \n",
    "    print \"There are \", cnt_16k, \" samples above 16kHz\"\n",
    "    print \"Non-zero DCT samples: \", non_zero_count\n",
    "    print \"Non-zero DCT percentage: \", round(float(non_zero_count)/(non_zero_count+zero_count)*100, 2), \"%\"\n",
    "#     fig, axs = plt.subplots(1)\n",
    "#     axs.plot(music[0:1030])\n",
    "#     axs.grid(True)\n",
    "#     axs.set_xlabel(\"x\")\n",
    "#     axs.set_ylabel(\"dct_y\")\n",
    "#     axs.set_title(\"HQ-music after dct process(NB=\"+str(NB)+\" threshold=\"+str(threshold)+\")\")\n",
    "    print(\"HQ-music after dct process(NB=\"+str(NB)+\" threshold=\"+str(threshold)+\")\")\n",
    "    Audio(music, rate=Fs)\n",
    "    ! rm \"HQ-music.bin\"\n",
    "    \n",
    "    \n",
    "dct_proc(16, 0, music)\n",
    "dct_proc(16, 500, music)\n",
    "dct_proc(16, 800, music)\n",
    "dct_proc(16, 2000, music)\n",
    "dct_proc(14, 500, music)\n",
    "dct_proc(12, 500, music)\n",
    "dct_proc(11, 500, music)\n",
    "dct_proc(8, 500, music)\n",
    "dct_proc(6, 500, music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4 Q&A:\n",
    "1. What saving in bit-rate can achieved by reducing the bandwidth to 16 kHz?\n",
    "   * If we use 16 bits for each sample, then we can save 241080x16/20 = 192864 bps.\n",
    "   * We can save 241080/882100 = 27% in percentage.\n",
    "2. What is the effect of varying the constant threshold? What happens with a value that \n",
    "   * (a) is definitely too high\n",
    "     * We may suffer distortion and severe clicking noises.\n",
    "   * (b) too low \n",
    "     * The quality will be better, but we may not save many bit-rates.\n",
    "   * (c) potentially satisfactory? Give the values.\n",
    "     * 500.\n",
    "3. For the 'potentially satisfactory' threshold, what is the effect of quantising the remaining non-zero DCT coefficients to 8 bits per sample?\n",
    "   * The clicking sounds become severe and the quality of music decreased.\n",
    "4. For the 'potentially satisfactory' threshold, and 8 bits per DCT coefficient, assuming that you could send the zero-valued DCT coefficients at negligible cost, what bit-rate is required by this coding procedure? What bit-rate saving (in percentage terms) is achieved?\n",
    "   * Bit-rate required: 194385x8/20 = 77754 bps.\n",
    "   * Bit-rate saving : (194385x8/20)/(882100x16/20)x100% = 89% \n",
    "5. Did you observe any distortion in the form of 'clicks' due to discontinuities at frame boundaries?\n",
    "   * Yes, especially when we use less number of bits.\n",
    "6. If so, what causes these clicks? Think carefully about this and consider why you do not get clicks until you start doing some frequency domain processing.\n",
    "   * It is caused by processing like setting samples under threshold to zeros and quantization, when we divide the original audio into segments, we are not likely to make every segment exactly is a period, therefore, there could be energy shared out among neighboring frequency-domain sampling point(leakage) happen at the boundaries of each frame. Since the idct is the inverse of dct, so we will not get any distortions if we do not apply any processing, however, if we do, there might be some errors when we use idct to get back to time-domain, especially at the boundaries of each segment(where we cut the wave), and if the ending of the previous frame do not get the similar value with the starting of the current frame, then the discontinuity occurs and we can hear clicking sound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.5 Simple method for eliminating discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "from scipy.fftpack import dct, idct\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio\n",
    "\n",
    "# read wavefile\n",
    "(Fs, music) = wavfile.read(\"HQ-music44100-mono.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "print(\"Original HQ-music44100-mono.wav:\")\n",
    "Audio(music, rate=Fs)\n",
    "\n",
    "step = 1024\n",
    "threshold = 2000\n",
    "NB = 16\n",
    "seg_count = 0\n",
    "\n",
    "with open (\"HQ-music.bin\", \"wb\") as f:\n",
    "    for i in range(0, len(music), step):\n",
    "        seg_count += 1\n",
    "        dctF = np.copy(music[i:i+step])\n",
    "        dctF = np.float32(dctF)\n",
    "        \n",
    "        # smooth the boundaries\n",
    "        if i == 0:\n",
    "            z = dctF[0]\n",
    "        for j in range(0, 3):\n",
    "            dctF[j] = (dctF[j] + z) / 2.0 \n",
    "        z = dctF[len(dctF)-1] # calculate z for smoothing boundaries\n",
    "        \n",
    "        dctF = dct(dctF, norm=\"ortho\")\n",
    "        \n",
    "        # set zeros\n",
    "        for j in range(0, len(dctF)):\n",
    "            if abs(dctF[j]) < threshold or Fs/2.0/step*j > 16000:\n",
    "                dctF[j] = 0\n",
    "        \n",
    "        # scale dctF\n",
    "        SM = 500000           # Get maximum amplitude\n",
    "        dctF = dctF/float(SM)    # Scale maximum to 1 (note the float)\n",
    "        # number per bits = NB\n",
    "        quant_dctF = np.round(dctF*(2**(NB-1)))\n",
    "        quant_dctF = np.int16(quant_dctF)\n",
    "        dctF = np.int16(quant_dctF * (2**(16-NB)))\n",
    "        \n",
    "        np.save(f, dctF)\n",
    "\n",
    "with open (\"HQ-music.bin\", \"rb\") as f:\n",
    "    idctF = np.load(f)\n",
    "    music = np.int16(idct(idctF, norm=\"ortho\"))\n",
    "    for i in range(1, seg_count):\n",
    "        idctF = np.load(f)\n",
    "        music = np.append(music, np.int16(idct(idctF, norm=\"ortho\"))) \n",
    "    \n",
    "SM = max(abs(music))\n",
    "music = music/float(SM)\n",
    "music = np.int16(music*32767)\n",
    "\n",
    "print \"Music after dct processing with smoothing work:\"\n",
    "Audio(music, rate=Fs)\n",
    "\n",
    "! rm \"HQ-music.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.5 Q&A:\n",
    "1. Describe the principle of your simple method and how it was implemented.\n",
    "   * The simple method is letting the starting samples of the frame to be closer to the ending sample of the previous frame. I calculate the first 3 starting points of the current frame and replaced them with the average value of them with the last sample of the previous frame.\n",
    "2. Does it work? If so how well does it work?\n",
    "   * To a certain extent, it works, but it is not working too well, for example, we can still hear some obvious clicking at around 8s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.6 Run-length & Huffman coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "from scipy.fftpack import dct, idct\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio\n",
    "\n",
    "# read wavefile\n",
    "(Fs, music) = wavfile.read(\"HQ-music44100-mono.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "\n",
    "seg_count = 0\n",
    "step = 1024\n",
    "threshold = 500\n",
    "NB = 8\n",
    "set_zeros = 0\n",
    "count_zeros = 0\n",
    "flag = 0\n",
    "\n",
    "with open (\"HQ-music.bin\", \"wb\") as f:\n",
    "    for i in range(0, len(music), step):\n",
    "        seg_count += 1\n",
    "        dctF = dct(music[i:i+step], norm=\"ortho\")\n",
    "        \n",
    "        # set zeros\n",
    "        for j in range(0, len(dctF)):\n",
    "            if abs(dctF[j]) < threshold or Fs/2.0/step*j > 16000:\n",
    "                dctF[j] = 0\n",
    "                set_zeros += 1\n",
    "                count_zeros += 1\n",
    "                if count_zeros > 255:\n",
    "                    count_zeros = 0\n",
    "                    flag += 1\n",
    "            else:\n",
    "                count_zeros = 0\n",
    "        if i == 0:\n",
    "            print \"For frame 1, there are \", step - set_zeros + flag, \" numbers require individual 8 bits\"\n",
    "            print \"For frame 1, Saving rate: \", round((1024.0*8-(step-set_zeros+flag)*16)/(1024.0*8)*100,1), \"%\"\n",
    "        \n",
    "        # scale dctF\n",
    "        SM = 400000        \n",
    "        dctF = dctF/float(SM)    # Scale maximum to 1 (note the float)\n",
    "         # number per bits = NB\n",
    "        quant_dctF = np.round(dctF*(2**(NB-1)))\n",
    "        quant_dctF = np.int16(quant_dctF)\n",
    "        dctF = np.int16(quant_dctF * (2**(16-NB)))\n",
    "            \n",
    "        idctF = np.int16(dctF)\n",
    "        np.save(f, idctF)\n",
    "\n",
    "with open (\"HQ-music.bin\", \"rb\") as f:\n",
    "    idctF = np.load(f)\n",
    "    music = np.int16(idct(idctF, norm=\"ortho\"))\n",
    "    for i in range(1, seg_count):\n",
    "        idctF = np.load(f)\n",
    "        music = np.append(music, np.int16(idct(idctF, norm=\"ortho\"))) \n",
    "\n",
    "print \"There are \", len(music) - set_zeros + flag, \" numbers require individual 8 bits in total\"\n",
    "print \"For whole file, Saving rate: \",round((len(music)*8.0-(len(music)-set_zeros+flag)*16)/(len(music)*8)*100,1),\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.6 Q&A:\n",
    "* Taking NB=8, threshold=500 as example:\n",
    "1. What bit-rate saving was achieved for the single frame by run-length coding of zeros? \n",
    "   * For the first frame, there are 1024 samples in total, and 160 non-zero samples among them, so if we use run-length coding, we only need 160x16 = 2560 bits compared with the traditional way which we need 1024x8 = 8192 bits, which means we saved 8192-2560 = 5632 bits, 5632/0.023 = 244870 bps, for the first frame.\n",
    "   * Saving rate percentage: 68.8%\n",
    "2. What bit-rate saving was achieved for the whole file by run-length coding of zeros?\n",
    "   * For the whole file, there are 882001 samples in total, and 197327 non-zero samples among them, so if we use run-length coding, we only need 197327x16 = 3,157,232 bits compared with the traditional way which we need 882001x8 = 7,056,008 bits, which means we saved 7,056,008-3,157,232 = 3,898,776 bits, 3,898,776/20 = 194,939 bps for the whole file.\n",
    "   * Saving rate percentage: 55.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.7 Eliminating discountinuities using overlapping frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "from scipy.fftpack import dct, idct\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio\n",
    "\n",
    "# read wavefile\n",
    "(Fs, music) = wavfile.read(\"HQ-music44100-mono.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "print(\"Original HQ-music44100-mono.wav:\")\n",
    "Audio(music, rate=Fs)\n",
    "\n",
    "\n",
    "def win_proc(NB, threshold, music):\n",
    "    \n",
    "    seg_count = 0\n",
    "    non_zero_count = 0\n",
    "    zero_count = 0\n",
    "    step = 1024\n",
    "   \n",
    "    with open (\"HQ-music.bin\", \"wb\") as f:\n",
    "        for i in range(0, len(music), step):\n",
    "            seg_count += 1\n",
    "            extendedFrame = music[i:i+step*2]\n",
    "            winextFrame = extendedFrame * np.hamming(len(extendedFrame))\n",
    "            dctF = dct(winextFrame, norm=\"ortho\")\n",
    "            # set zeros\n",
    "            for j in range(0, len(dctF)):\n",
    "                if abs(dctF[j]) < threshold or Fs/2.0/step*j > 16000:\n",
    "                    dctF[j] = 0\n",
    "                    zero_count+=1\n",
    "                else:\n",
    "                    non_zero_count+=1\n",
    "            # scale dctF\n",
    "            SM = 400000           \n",
    "            dctF = dctF/float(SM)    # Scale maximum to 1 (note the float)\n",
    "            # number per bits = NB\n",
    "            quant_dctF = np.round(dctF*(2**(NB-1)))\n",
    "            quant_dctF = np.int16(quant_dctF)\n",
    "            dctF = np.int16(quant_dctF * (2**(16-NB)))\n",
    "            np.save(f, dctF)\n",
    "\n",
    "    with open (\"HQ-music.bin\", \"rb\") as f:\n",
    "        idctF = np.load(f)\n",
    "        music = np.int16(idct(idctF, norm=\"ortho\"))\n",
    "        preFrame = music[1024:2048]\n",
    "        music = music[0:1024]\n",
    "        for i in range(1, seg_count):\n",
    "            idctF = np.load(f)\n",
    "            idctF = np.int16(idct(idctF, norm=\"ortho\"))\n",
    "            nextF = idctF[0:1024] + preFrame\n",
    "            preFrame = idctF[1024:len(idctF)]\n",
    "            music = np.append(music, nextF) \n",
    "    SM = max(abs(music))\n",
    "    music = music/float(SM)\n",
    "    music = np.int16(music*32767)\n",
    "    \n",
    "    print \"Non-zero DCT samples: \", non_zero_count\n",
    "    print \"Non-zero DCT samples per frame: \", round(float(non_zero_count)/(seg_count), 1)\n",
    "\n",
    "    print(\"HQ-music after dct process(NB=\"+str(NB)+\" threshold=\"+str(threshold)+\")\")\n",
    "    Audio(music, rate=Fs)\n",
    "    ! rm \"HQ-music.bin\"\n",
    "    \n",
    "\n",
    "win_proc(16, 3000, music)\n",
    "win_proc(16, 1500, music)\n",
    "win_proc(16, 800, music)\n",
    "win_proc(12, 800, music)\n",
    "win_proc(10, 800, music)\n",
    "win_proc(9, 800, music)\n",
    "win_proc(8, 800, music)\n",
    "win_proc(7, 0, music)\n",
    "win_proc(6, 0, music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.7 Q&A:\n",
    "1. With the best threshold for constant masking, how many non-zero DCT coefficients are there per frame on average?\n",
    "   * About 255 coefficients.\n",
    "2. How many bits per DCT coefficient did you find are really needed?\n",
    "   * 10 bits, otherwise the clicking sound can be heard.\n",
    "3. If we could find a way of sending the zero valued DCT coefficients at no cost (or very little cost), estimate the bit-rate saving that would result from the three techniques considered above.\n",
    "   * If we use hamming window, threshold=800, NB=10, then we will have 219756(compared to 882100) non-zero dct samples, so we will save 882100x16-219756x10 = 11,916,040 bits, which is 11,916,040/20 = 595802 bps in terms of bit-rate, and 1-(219756x10)/(882100x16)=84.4% in terms of percentage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
