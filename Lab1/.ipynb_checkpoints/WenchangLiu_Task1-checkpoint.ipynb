{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP28512 Laboratory Task1: Sound Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1. Generating and listening to sine-waves\n",
    "### Python function playSin(F, Fs):\n",
    "Generate an \"int16\" numpy array containing a sine-wave of amplitude 30000 and frequency F(Hz).\n",
    "The sine-wave must be sampled at Fs Hz and last for 3 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import int16\n",
    "from comp28512_utils import Audio\n",
    "\n",
    "\n",
    "def playSin(F, Fs):\n",
    "    T = 1.0/Fs # sampling period(seconds)\n",
    "    A = 30000 # amplitude\n",
    "    last = int(3//T+1)\n",
    "    n = np.arange(0, last)\n",
    "    y = np.array([0]*last, int16)\n",
    "    y = int16(A*np.sin(2*np.pi*F*n*T)) # y=Asin(2pifnT)\n",
    "    Audio(y, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call playSin(F, Fs) twice with Fs = 44100Hz, F = 220Hz and 440Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sine-wave audio with amplitude 30000, frequency 220Hz, sampling frequency 44100Hz.\")\n",
    "playSin(220, 44100)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 440Hz, sampling frequency 44100Hz.\")\n",
    "playSin(440, 44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call playSin(F, Fs) for F: 1000Hz, 2000Hz, 4000Hz, 8000Hz, 16000Hz, 18000Hz, 20000Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sine-wave audio with amplitude 30000, frequency 1000Hz, sampling frequency 44100Hz.\")\n",
    "playSin(1000, 44100)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 2000Hz, sampling frequency 44100Hz.\")\n",
    "playSin(2000, 44100)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 4000Hz, sampling frequency 44100Hz.\")\n",
    "playSin(4000, 44100)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 8000Hz, sampling frequency 44100Hz.\")\n",
    "playSin(8000, 44100)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 16000Hz, sampling frequency 44100Hz.\")\n",
    "playSin(16000, 44100)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 18000Hz, sampling frequency 44100Hz.\")\n",
    "playSin(18000, 44100)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 20000Hz, sampling frequency 44100Hz.\")\n",
    "playSin(20000, 44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 Q&A:\n",
    "1. Describe the sound produced by a sine-wave of frequency 220 Hz.\n",
    "   * The sound is kind of low and consistent, representing music note \"A\" near middle C. \n",
    "2. How does the sound differ from that produced by musical instruments and the human voice?\n",
    "   * The tones heard different. This sound is not naturally produced and it will not faded over time.\n",
    "3. Describe any differences and similarities between the sound at F=220 to F=440.\n",
    "   * Differences: F=440 sounds \"sharper\" than F=220.\n",
    "   * Similarities: They both represent music note \"A\", and they are both steady which is kind of \"artificial\".\n",
    "4. What is the highest frequency you could hear?\n",
    "   * For very high volume, 20000Hz, for lower volume, 16000Hz.\n",
    "5. Could there be other factors that affect your answer to question 4?\n",
    "   * Different devices and headphones may have different results.\n",
    "6. Why is it best not to use ‘for’ loops for this software?\n",
    "   * Because the data we have to deal with is too much, and \"for\" loops are slower than numpy, so we can save a lot of time using numpy instead of 'for' loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2. Demonstration of aliasing for sine-waves\n",
    "### call playSin(F, Fs) with Fs=4000Hz, and F from 500-3.5kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sine-wave audio with amplitude 30000, frequency 500Hz, sampling frequency 4000Hz.\")\n",
    "playSin(500, 4000)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 1kHz, sampling frequency 4000Hz.\")\n",
    "playSin(1000, 4000)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 1.5kHz, sampling frequency 4000Hz.\")\n",
    "playSin(1500, 4000)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 2kHz, sampling frequency 4000Hz.\")\n",
    "playSin(2000, 4000)\n",
    "print(\"The following audio has sampling frequency Fs < 2*F, so there should be aliasing distorion:\")\n",
    "print\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 2.5kHz, sampling frequency 4000Hz.\")\n",
    "playSin(2500, 4000)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 3kHz, sampling frequency 4000Hz.\")\n",
    "playSin(3000, 4000)\n",
    "print(\"sine-wave audio with amplitude 30000, frequency 3.5kHz, sampling frequency 4000Hz.\")\n",
    "playSin(3500, 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Q&A:\n",
    "1. Why does aliasing distortion occur in this experiment?\n",
    "   * Because sampling frequency is not high enough(sampling frequency < 2* sine-wave max frequency) when we increasing the frequency of the sine-wave.\n",
    "2. What is the effect of aliasing on each of the six sine-waves?\n",
    "   * For the first 3 sine-waves(500, 1k, 1.5k), we can still reconstruct the sound with our sampling, but the last 3 sine-waves(2.5k, 3k, 3.5k), we cannot and the sound we listened is not the real sine-wave sound at those frequency, in fact, they sound like 1.5k, 2k, 500 Hz sine-wave respectively.\n",
    "3. Explain what happens when F = 2000 Hz.\n",
    "   * It has no sound coming out since we always sample at \"amplitude=0\" points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3. Processing a music file to demonstrate aliasing\n",
    "### Reads violin music, reduce the sampling frequency without filter, and then use \"decimate\" or \"resample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import int16\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio\n",
    "from scipy.signal import decimate, resample\n",
    "# read music from wavfile\n",
    "(Fs, violin_music) = wavfile.read(\"SVivaldi44.1mono.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "print(\"Unmodified violin music:\")\n",
    "Audio(violin_music, rate=Fs)\n",
    "# reduce sampling frequency by a factor of 11 without antialiasing filter\n",
    "n = np.arange(0, violin_music.size/11)\n",
    "violin_r = violin_music[n*11]\n",
    "print(\"Violin music with reducing sampling frequency by 11:\")\n",
    "Audio(violin_r, rate=Fs/11)\n",
    "# decimate and resample\n",
    "violin_r = decimate(violin_music, 11, zero_phase=True).astype(int16)\n",
    "print(\"Decimated violin music:\")\n",
    "Audio(violin_r, rate=Fs/11)\n",
    "# why is resample slower than decimate?\n",
    "violin_r = resample(violin_music, (violin_music.size)/11).astype(int16)\n",
    "print(\"Resampled violin music:\")\n",
    "Audio(violin_r, rate=Fs/11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 Q&A:\n",
    "1. How does your program know what is the original sampling frequency?\n",
    "   * We can get the sampling frequency by get the return value of wavfile.read function.\n",
    "2. Could you hear any distortion in the original wav file?\n",
    "   * No, maybe there are some distortion but definitely not obvious.\n",
    "3. Describe the two effects you heard with the sampling frequency reduced to about 4 kHz without antialiasing filtering.\n",
    "   * Some distortions like pitch is lower and inaccurate tunes.\n",
    "   * Some musical notes became muffled.\n",
    "4. What was the effect of the antialiasing filtering when you used 'resample' or 'decimate'?\n",
    "   * The sound becomes decent, but not as good as the original one.\n",
    "5. How does the aliasing distortion affect musical notes?\n",
    "   * The musical notes could sound off the pitch and become muffled.\n",
    "6. Is an antialiasing filter always necessary before sampling music?\n",
    "   * Yes, we will need filter when there are sounds which have frequency more than half of our sampling frequency, since we cannot know our recorded music(including some noises)'s maximum frequency, we will need a low pass filter to ensure that no high frequency sounds which may cause aliasing distortion exist before we sample the music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.4. Reducing the bit-rate of a speech or music file by reducing the sampling frequency\n",
    "### Use the 'decimate' function with different sampling rates for the high quality speech file and the high quality music file to avoid aliasing distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import int16\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio\n",
    "from scipy.signal import decimate, resample\n",
    "# read music from wavfile\n",
    "(Fs, speech) = wavfile.read(\"HQ-speech44100-mono.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "# print(\"Unmodified HQ-speech:\")\n",
    "# Audio(speech, rate=Fs)\n",
    "s_factor = 8\n",
    "# decimate by factor\n",
    "speech_r = decimate(speech, s_factor, zero_phase=True).astype(int16)\n",
    "print \"Decimated HQ-speech by factor\", s_factor, \" :\"\n",
    "Audio(speech_r, rate=Fs/s_factor)\n",
    "# read music from wavfile\n",
    "(Fs, music) = wavfile.read(\"HQ-music44100-mono.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "# print(\"Unmodified HQ-music:\")\n",
    "# Audio(music, rate=Fs)\n",
    "m_factor = 3\n",
    "# decimate by factor\n",
    "music_r = decimate(music, m_factor, zero_phase=True).astype(int16)\n",
    "print \"Decimated HQ-music by factor\", m_factor, \" :\"\n",
    "Audio(music_r, rate=Fs/m_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.4 Q&A:\n",
    "1. What is the effect on speech of reducing the sampling rate ?\n",
    "   * The sound can get indecipherable and have some noises in background if the reducing factor is high.\n",
    "2. What you consider to be the minimum acceptable sampling rate forspeech that you would like to hear from the built in speaker of your mobile phone?\n",
    "   * 5512.5Hz(Factor 8).\n",
    "3. What is the effect on music of reducing the sampling rate ?\n",
    "   * The sound will get muffled, and if the reducing factor is high, then the sound can get have noises in background.\n",
    "4. What you consider to be the minimum acceptable sampling rate for music that you would like to hear from your mobile phonewhen using headphones or a good quality speaker?\n",
    "   * 14700Hz(Factor 3) is acceptable, but I would like the HQ soundtrack if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.5. Reducing the bit-rate for music by reducing number of bits per sample\n",
    "### Compare the HQ-music original and quantised to specific 'NB' version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import int16\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio\n",
    "# read music from wavfile\n",
    "(Fs, music) = wavfile.read(\"HQ-music44100-mono.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "print(\"Original(NB=16) HQ-music:\")\n",
    "Audio(music, rate=Fs)\n",
    "# quantised version\n",
    "SM = max(abs(music))           # Get maximum amplitude\n",
    "music = music/float(SM)    # Scale maximum to 1 (note the float)\n",
    "\n",
    "\n",
    "def HQ_quant(NB, music): \n",
    "    quant_music = np.round(music*(2**(NB-1)-0.5)-0.5)\n",
    "    iquant_music = np.int16(quant_music)\n",
    "    iquant_music = int16((iquant_music+0.5) * (2**(16-NB)))\n",
    "    print \"Quantised music using \", NB, \" per sample:\"\n",
    "    Audio(iquant_music, rate=Fs)\n",
    "\n",
    "\n",
    "for i in range(15, 2, -1):\n",
    "    if i == 5:\n",
    "        print \"Minimum acceptable, can hear some noises but not much:\"\n",
    "    HQ_quant(i, music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.5 Q&A:\n",
    "1. What do you consider to be the minimum acceptable value of NB for music sampled at 44.1 kHz?\n",
    "   * NB=5, because the sound is clear, but NB=4 is not.\n",
    "2. Describe the distortion that occurs as NB is decreased from 16 towards 3.\n",
    "   * The sound has little changes when NB is above 6, we can hear some noises in NB=5 version, and the noises become much more severe when NB=4 or 3.\n",
    "3. Does the nature of the distortion change when the number of bits per sample becomes three or less?\n",
    "   * The nature does not change, but it is more severe when NB=3 or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.6. Telephone quality speech\n",
    "### Evaluate uniform quantisation effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import int16\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio, get_pesq_scores, audio_from_file \n",
    "# read speech from wavfile\n",
    "(Fs, nbSpeech) = wavfile.read(\"NarrobandSpeech8k.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "print(\"Original Narrrowbandspeech:\")\n",
    "Audio(nbSpeech, rate=Fs)\n",
    "\n",
    "\n",
    "def uniform_quant(NB, nbSpeech):\n",
    "    # scale to [-1, 1]\n",
    "    SM = max(abs(nbSpeech))           # Get maximum amplitude\n",
    "    nbSpeech = nbSpeech/float(SM)    # Scale maximum to 1 (note the float)\n",
    "    # number per bits = NB\n",
    "    quant_speech = np.round(nbSpeech*(2**(NB-1)-0.5)-0.5)\n",
    "    iquant_speech = int16(quant_speech)\n",
    "    iquant_speech = int16((iquant_speech+0.5) * (2**(16-NB)))\n",
    "    print \"Quantised narrowband speech using \", NB, \" per sample:\"\n",
    "    nb_speech_file = \"speechNB\"+str(NB)+\".wav\"\n",
    "    wavfile.write(nb_speech_file, Fs, iquant_speech)\n",
    "    audio_from_file(nb_speech_file)\n",
    "    # score PESQ\n",
    "    ! rm pesq_results.txt\n",
    "    # Running PESQMain (in working directory with ‘chmod a+x’ set ) to obtain PESQ-MOS score:\n",
    "    ! ./linux_pesqmain +8000 NarrobandSpeech8k.wav $nb_speech_file > /dev/null\n",
    "    # comp28512_utils must be in working directory\n",
    "    pesq_results = get_pesq_scores()\n",
    "    score = pesq_results[\"NarrobandSpeech8k.wav\"] [nb_speech_file] \n",
    "    print \"PESQMain score for NarrobandSpeech8k.wav against \"+nb_speech_file+\" = \", score\n",
    "    print\n",
    "    \n",
    "\n",
    "uniform_quant(10, nbSpeech) # NB=10\n",
    "uniform_quant(8, nbSpeech) # NB=8\n",
    "uniform_quant(6, nbSpeech) # NB=6\n",
    "uniform_quant(4, nbSpeech) # NB=4\n",
    "uniform_quant(3, nbSpeech) # NB=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.6 Q&A:\n",
    "1. Can you hear any difference between the original 16 bit per sample version and your 8 bit version? \n",
    "   * There seems to be some slight noises in the background for 8 bit version.\n",
    "2. Taking ‘Narrobandspeech8k.wav’ as the reference, what are the PESQ scores for \n",
    "   * (a) your 8 bit per sample version 3.834\n",
    "   * (b) a 4-bit per sample version 2.338\n",
    "   * (c) any others you tested? Yes, NB=10: 4.238; NB=6: 3.005; NB=3: 2.037   \n",
    "3. Compare your own assessments with the PESQ scores obtained for several values of NB.\n",
    "   * Basically the same, the sounds with higher scores are higher in quality for me. \n",
    "4. Decide what you consider to be a reasonable number of bits (NB) per sample for telephone speech when the sampling rate is 8 kHz with uniform quantisation. Summarise your reasons in one sentence, and note whether your decision is significantly different from the PESQ assessment. \n",
    "   * I think NB=6 could be appropriate, since the sound quality is decent and clear, and compared to PESQ score, just a little under \"good\" according to PESQ MOS score table.\n",
    "5. You have heard that land-line telephone calls use 64000 bits/second links. Based on your experiments today, do you consider that 8 bits per sample with uniform quantisation may be acceptable for telephone quality speech sampled at 8 kHz? \n",
    "   * Yes, as long as the sounds are decipherable and does not have too much noises. I think 6 bits per sample is acceptable, 8 bits will be even better.\n",
    "6. Mobile telephony cannot afford 64000 bits/second, and must use considerably less than 16,000  bits/second. \n",
    "   * How  many bits per sample would be possible using 16000 bits/second with uniform quantisation of speech sampled at 8 kHz?\n",
    "     * NB = 16000/8000 = 2 bits\n",
    "   * Based  on  your experiments, do you believe that reasonable quality speech can be encoded in this way for mobile telephony?\n",
    "     * No, do not think the quality can reach a reasonable state, the sounds could be so unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.7. Log-PCM encoding speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import int16\n",
    "from scipy.io import wavfile\n",
    "from comp28512_utils import Audio, audio_from_file, get_pesq_scores \n",
    "% matplotlib inline\t\n",
    "\n",
    "# mulaw function and inverse\n",
    "def mu_law(x):\n",
    "    mu = 255\n",
    "    y = np.sign(x)*np.log(1+mu*abs(x))/np.log(1+mu)\n",
    "    return y\n",
    "\n",
    "\n",
    "def inverse_mu_law(y): \n",
    "    mu = 255\n",
    "    u = np.sign(y)*(np.exp(np.log(1+mu)*abs(y))-1)/mu\n",
    "    return u\n",
    "\n",
    "\n",
    "# plot compressor and expander\n",
    "fig, axs = plt.subplots(1)\n",
    "xc = np.arange(-1, 1, 0.01)\n",
    "yc = mu_law(xc)\n",
    "axs.plot(xc, yc)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"Before companding: x\") \n",
    "axs.set_ylabel(\"After companding(mu-law(x)): y\")\n",
    "axs.set_title(\"Compressor Graph(output y against input x)\")\n",
    "\n",
    "fig, axs = plt.subplots(1)\n",
    "xe = np.arange(-1, 1, 0.01)\n",
    "ye = inverse_mu_law(xe)\n",
    "axs.plot(xe, ye)\n",
    "axs.grid(True)\n",
    "axs.set_xlabel(\"Before expanding: y\") \n",
    "axs.set_ylabel(\"After expanding(inverse-mu-law(y)): u\")\n",
    "axs.set_title(\"Expander Graph(output u against input y)\")\n",
    "\n",
    "# read speech from wavfile\n",
    "(Fs, speech) = wavfile.read(\"NarrobandSpeech8k.wav\")\n",
    "print \"Sampling frequency Fs as read from wav-file: \",Fs,\" Hz\"\n",
    "\n",
    "\n",
    "def quant_cmp(NB, speech):\n",
    "    # scale to [-1, 1]\n",
    "    SM = max(abs(speech))  # Get maximum amplitude\n",
    "#     print where(abs(speech)==max(abs(speech)))\n",
    "#     print abs(speech)[108630]\n",
    "#     print abs(speech)[101515]\n",
    "    speech = speech/float(SM)    # Scale maximum to 1 (note the float)\n",
    "    \n",
    "    \n",
    "    # mu-law NB = 8\n",
    "    mu_speech = mu_law(speech)\n",
    "    SM = max(abs(mu_speech))           # Get maximum amplitude\n",
    "    mu_speech = mu_speech/float(SM)    # Scale maximum to 1 (note the float)\n",
    "    quant_speech = np.round(mu_speech*(2**(NB-1)-0.5)-0.5)\n",
    "    iquant_speech = int16(quant_speech)\n",
    "    iquant_speech = int16((iquant_speech+0.5) * (2**(16-NB)))\n",
    "    \n",
    "    SM = max(abs(iquant_speech))           # Get maximum amplitude\n",
    "    iquant_speech = iquant_speech/float(SM)    # Scale maximum to 1 (note the float)\n",
    "    iquant_speech = inverse_mu_law(iquant_speech)\n",
    "    # quantisize to 16 bit\n",
    "    mu_speech = int16(iquant_speech * (2**15))\n",
    "    print(\"NB=\"+str(NB)+\" mu-law speech:\")\n",
    "    mu_file_name = \"mu-law\"+str(NB)+\".wav\"\n",
    "    wavfile.write(mu_file_name, Fs, mu_speech)\n",
    "    audio_from_file(mu_file_name)\n",
    "    \n",
    "    # uniform version NB = 8\n",
    "    quant_speech = np.round(speech*(2**(NB-1)-0.5)-0.5)\n",
    "    iquant_speech = int16(quant_speech)\n",
    "    iquant_speech = int16((iquant_speech+0.5) * (2**(16-NB)))\n",
    "    print(\"NB=\"+str(NB)+\" uniform quantisation speech:\")\n",
    "    file_name = \"speechNB\"+str(NB)+\".wav\"\n",
    "    wavfile.write(file_name, Fs, iquant_speech)\n",
    "    audio_from_file(file_name)\n",
    "\n",
    "    # score PESQ\n",
    "    ! rm pesq_results.txt\n",
    "    # Running PESQMain (in working directory with ‘chmod a+x’ set ) to obtain PESQ-MOS score:\n",
    "    ! ./linux_pesqmain +8000 NarrobandSpeech8k.wav $mu_file_name > /dev/null\n",
    "    pesq_results = get_pesq_scores()\n",
    "    score = pesq_results[\"NarrobandSpeech8k.wav\"] [mu_file_name] \n",
    "    print \"PESQMain score for NarrobandSpeech8k.wav against \"+mu_file_name+\" = \", score\n",
    "    \n",
    "    ! rm pesq_results.txt\n",
    "    # Running PESQMain (in working directory with ‘chmod a+x’ set ) to obtain PESQ-MOS score:\n",
    "    ! ./linux_pesqmain +8000 NarrobandSpeech8k.wav $file_name > /dev/null\n",
    "    pesq_results = get_pesq_scores()\n",
    "    score = pesq_results[\"NarrobandSpeech8k.wav\"] [file_name] \n",
    "    print \"PESQMain score for NarrobandSpeech8k.wav against \"+file_name+\" = \", score\n",
    "    \n",
    "    print\n",
    "\n",
    "    \n",
    "quant_cmp(8, speech)\n",
    "quant_cmp(7, speech)\n",
    "quant_cmp(6, speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.7 Q&A:\n",
    "1. What do we learn from the mu-law companding and expansion graphs?\n",
    "   * expansion is the inverse version of companding.\n",
    "   * mu-law increase the bits used for low values(closed to 0) rather than uniformly quantisation.\n",
    "2. Compare mu-Law PCM speech at 64000 bit/s with the result of uniform quantisation at the same bit-rate. Give PESQ scores and your own assessments for both.\n",
    "   * It is much better than the uniform quantisation version, according to PESQ scores. And for me, I can tell the difference between them and clearly mu-law version is better.\n",
    "3. If you have time, compare mu-Law PCM speech with NB=7, 6, etc. with result of uniform quantisation at the same bit-rate (56,000 bit/s, 48,000 bit/s, etc).\n",
    "   * For NB=7 and NB=6, mu-law versions are all better(clearer and less noises) than uniform quantisation version."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
