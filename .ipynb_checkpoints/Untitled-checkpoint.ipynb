{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named comp28512_utils",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6832fcf2156b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcomp28512_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplaySin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30000.0\u001b[0m                 \u001b[0;31m# amplitude of sine-wave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mFs\u001b[0m                \u001b[0;31m# Sampling period (seconds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named comp28512_utils"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import comp28512_utils as utils \n",
    "def playSin(F,Fs):\n",
    "    A = 30000.0                 # amplitude of sine-wave\n",
    "    T = 1.0 / Fs                # Sampling period (seconds)\n",
    "    n = numpy.arange(0, 150000) # Makes n a Numpy array of 0*T, 1*T, … 150000*T\n",
    "    y =  A * numpy.sin( 2 * numpy.pi * F * n * T )\n",
    "    sin_audio = numpy.int16(y) \n",
    "    utils.Audio(sin_audio, rate=Fs,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "playSin(220,44100)\n",
    "playSin(440,44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playSin(1000,44100)\n",
    "playSin(2000,44100)\n",
    "playSin(4000,44100)\n",
    "playSin(8000,44100)\n",
    "playSin(16000,44100)\n",
    "playSin(18000,44100)\n",
    "playSin(20000,44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 1.1 Qusetions:\n",
    "1.Describe the sound produced by a sine-wave of frequency 220 Hz.  \n",
    "   -It sounds like 'do' in terms of tune.\n",
    "   \n",
    "2.How does the sound differ from that produced by musical instruments and the human voice?\n",
    "   -Component frequencies of music are discrete and rational with a discernible dominant frequency;\n",
    "   -Component frequencies of noise are continuous and random with no discernible dominant frequency.\n",
    "   \n",
    "3.Describe any differences and similarities between the sound at F=220 to F = 440. \n",
    "   -Differences: sound at F=440Hz is higher in terms of tune than that at F=220Hz;\n",
    "   -Similarities: they are all continuous.\n",
    "   \n",
    "4.What is the highest frequency you could hear? \n",
    "   -16kHz from earphone, 18kHz from microphone\n",
    "   \n",
    "5.Could there be other factors that affect your answer to question 4? \n",
    "   -Quality of earphone and microphone\n",
    "   \n",
    "6.Why is it best not to use ‘for’ loops for this software? \n",
    "   -The list we produce is pretty long so using a loop can be time-consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,8):\n",
    "    print(\"F=%d Hz\"%(500*n))\n",
    "    playSin(500*n,4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 1.2 Qusetions:\n",
    "1.Why does aliasing distortion occur in this experiment? \n",
    "   -To avoid aliasing distortion, we need to keep F<0.5×Fs, that is F less than 2kHz. When F is above the value aliasing distortion will occur.\n",
    "   \n",
    "2.What is the effect of aliasing on each of the six sine-waves?   \n",
    "   -sound at 3.5kHz sounds pretty like that of 0.5kHz; sound at 3kHz sounds pretty like that of 1kHz; sound at 1.5kHz sounds pretty like that of 2kHz;\n",
    "   \n",
    "3.Explain what happens when F = 2000 Hz.\n",
    "   -Since F accidentlally becomes half of Fs, each sample has an amplitute of 0, so the audio if silent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile \n",
    "(sampling_freq, y) = wavfile.read(\"SVivaldi44.1mono.wav\"); \n",
    "utils.Audio(y, rate=sampling_freq,) \n",
    "# rasampling without antialiasing filter\n",
    "print('rasampling without antialiasing filter')\n",
    "n = numpy.arange(0 , y.size/11)\n",
    "y_wo = y[n*11]\n",
    "utils.Audio(y_wo, rate=sampling_freq/11,)\n",
    "# rasampling with resample()\n",
    "print('rasampling with resample()')\n",
    "from scipy.signal import resample\n",
    "y_re = resample(y, (y.size)/11); \n",
    "y_re = numpy.int16(y_re)\n",
    "utils.Audio(y_re, rate=sampling_freq/11,)\n",
    "# rasampling with decimate()\n",
    "print('rasampling with decimate()')\n",
    "from scipy.signal import decimate\n",
    "y_de = decimate(y, 11) \n",
    "y_de = numpy.int16(y_de)\n",
    "utils.Audio(y_de, rate=sampling_freq/11,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.3 Qusetions:\n",
    "1.How does your program know what is the original sampling frequency? \n",
    "   -Function wavfile.read() reads it from original wav file.\n",
    "   \n",
    "2.Could you hear any distortion in the original wav file? \n",
    "   -No\n",
    "   \n",
    "3.Describe the two effects you heard with the sampling frequency reduced to about 4 kHz without antialiasing filtering. \n",
    "   -Musical notes has been lowered; some extra noises appear in script.\n",
    "   \n",
    "4.What was the effect of the antialiasing filtering when you used 'resample' or 'decimate'? \n",
    "   -The tune of music is basically unchanged, yet it sounds more blurred.\n",
    "   \n",
    "5.How does the aliasing distortion affect musical notes? \n",
    "   -musical notes are generally lowered.\n",
    "   \n",
    "6.Why is it best not to use ‘for’ loops for this software? \n",
    "   -Not always. If decreasing factor is less than 2 or an increasing factor is used then no antialiasing filter is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('speech')\n",
    "(Fs_spe, y_spe) = wavfile.read(\"HQ-speech44100-mono.wav\"); \n",
    "utils.Audio(y_spe, rate=Fs_spe,)    # play original speech\n",
    "y_spe_re = resample(y_spe, (y_spe.size)/10);    #resample\n",
    "y_spe_re = numpy.int16(y_spe_re)\n",
    "utils.Audio(y_spe_re, rate=Fs_spe/10,)  # play resampled speech\n",
    "print('music')\n",
    "(Fs_msc, y_msc) = wavfile.read(\"HQ-music44100-mono.wav\"); \n",
    "utils.Audio(y_msc, rate=Fs_msc,)    # play original music\n",
    "y_msc_re = resample(y_msc, (y_msc.size)/3);   #resample\n",
    "y_msc_re = numpy.int16(y_msc_re)\n",
    "utils.Audio(y_msc_re, rate=Fs_msc/3)  # play resampled music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.4 Qusetions:\n",
    "1.What is the effect on speech of reducing the sampling rate? \n",
    "   -Words become harder to recognise and volumn gets lower.\n",
    "   \n",
    "2.What you consider to be the minimum acceptable sampling rate for speech that you would like to hear from the built in speaker of your mobile phone?\n",
    "   -[44100/10/100]×100=4410Hz\n",
    "   \n",
    "3.What is the effect on music of reducing the sampling rate ? \n",
    "   -It becomes more blurred.\n",
    "   \n",
    "4.What you consider to be the minimum acceptable sampling rate for music that you would like to hear from your mobile phone when using headphones or a good quality speaker?\n",
    "   -[44100/3/100]×100=14700Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(Fs_msc, y_msc) = wavfile.read(\"HQ-music44100-mono.wav\"); \n",
    "utils.Audio(y_msc, rate=Fs_msc,)    # play original music\n",
    "#y_cmp = numpy.round(y_msc / (2**15 - 1))  #compress music so that -1<=y_msc<=1\n",
    "SM=max(abs(y_msc))           # Get maximum amplitude \n",
    "y_cmp = y_msc/float(SM)    # Scale maximum to 1\n",
    "n = input(\"Enter NB: \") \n",
    "n = 16 - n \n",
    "# expansion to specified bits\n",
    "if n <8:\n",
    "    quant_y = numpy.round(y_cmp * (2**(15-n) - 1))\n",
    "else:\n",
    "    quant_y = numpy.round(y_cmp * (2**(15-n) - 0.5) -0.5) \n",
    "iquant_y = numpy.int16(quant_y)\n",
    "# expansion to playable version\n",
    "if n <8:\n",
    "    iquant_y = iquant_y*(2**n)\n",
    "else:\n",
    "    iquant_y = (iquant_y+0.5)*(2**n)\n",
    "    iquant_y = numpy.int16(iquant_y)\n",
    "print('%d bits remained'%(16-n))\n",
    "utils.Audio(iquant_y, rate=Fs_msc,)    # play rendered music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.5 Qusetions:\n",
    "1.What do you consider to be the minimum acceptable value of NB for music sampled at 44.1 kHz?\n",
    "   -NB=7\n",
    "   \n",
    "2.Describe the distortion that occurs as NB is decreased from 16 towards 3. \n",
    "   -When NB>=7, no obvirous distortion occurs; From NB=6 to 3, background noises becomes louder.\n",
    "   \n",
    "3.Does the nature of the distortion change when the number of bits per sample becomes three or less?\n",
    "   -No, because both sampling rate and audio rate has not changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm pesq_results.txt\n",
    "(Fs_spe, y_spe) = wavfile.read(\"NarrobandSpeech8k.wav\"); \n",
    "utils.Audio(y_spe, rate=Fs_spe,)    # play original speech\n",
    "#y_cmp = numpy.round(y_spe / (2**15 - 1))  #compress speech so that -1<=y_msc<=1\n",
    "SM=max(abs(y_spe))           # Get maximum amplitude \n",
    "y_cmp = y_spe/float(SM)    # Scale maximum to 1\n",
    "quant_y = numpy.round(y_cmp * (2**9 - 1)) # expansion to NB=10\n",
    "iquant_y = numpy.int16(quant_y)\n",
    "iquant_y = iquant_y*(2**6) # expansion to playable version\n",
    "print('rendered speech with NB=10')\n",
    "wavfile.write(\"NB=10_in_Part1-6.wav\", Fs_spe, iquant_y);\n",
    "utils.audio_from_file(\"NB=10_in_Part1-6.wav\")  # play rendered speech from file\n",
    "quant_y = numpy.round(y_cmp * (2**7 - 1)) # expansion to NB=8\n",
    "iquant_y = numpy.int16(quant_y)\n",
    "iquant_y = iquant_y*(2**8) # expansion to playable version\n",
    "print('rendered speech with NB=8')\n",
    "wavfile.write(\"NB=8_in_Part1-6.wav\", Fs_spe, iquant_y);\n",
    "utils.audio_from_file(\"NB=8_in_Part1-6.wav\")  # play rendered speech from file\n",
    "quant_y = numpy.round(y_cmp * (2**6 - 1)) # expansion to NB=7\n",
    "iquant_y = numpy.int16(quant_y)\n",
    "iquant_y = iquant_y*(2**8) # expansion to playable version\n",
    "print('rendered speech with NB=7')\n",
    "wavfile.write(\"NB=7_in_Part1-6.wav\", Fs_spe, iquant_y);\n",
    "quant_y = numpy.round(y_cmp * (2**5 - 1)) # expansion to NB=6\n",
    "iquant_y = numpy.int16(quant_y)\n",
    "iquant_y = iquant_y*(2**10) # expansion to playable version\n",
    "print('rendered speech with NB=6')\n",
    "wavfile.write(\"NB=6_in_Part1-6.wav\", Fs_spe, iquant_y);\n",
    "utils.audio_from_file(\"NB=6_in_Part1-6.wav\")  # play rendered speech from file\n",
    "quant_y = numpy.round(y_cmp * (2**3 - 1)) # expansion to NB=4\n",
    "iquant_y = numpy.int16(quant_y)\n",
    "iquant_y = iquant_y*(2**12) # expansion to playable version\n",
    "print('rendered speech with NB=4')\n",
    "utils.Audio(iquant_y, rate=Fs_spe,)    # play rendered speech\n",
    "quant_y = numpy.round(y_cmp * (2**2 - 1)) # expansion to NB=3\n",
    "iquant_y = numpy.int16(quant_y)\n",
    "iquant_y = iquant_y*(2**13) # expansion to playable version\n",
    "print('rendered speech with NB=3')\n",
    "wavfile.write(\"NB=3_in_Part1-6.wav\", Fs_spe, iquant_y);\n",
    "utils.audio_from_file(\"NB=3_in_Part1-6.wav\")  # play rendered speech from file\n",
    "\n",
    "# audio comparison\n",
    "from comp28512_utils import get_pesq_scores \n",
    "# compare NB=8 with reference audio\n",
    "! ./linux_pesqmain +8000 NarrobandSpeech8k.wav NB=8_in_Part1-6.wav > /dev/null\n",
    "pesq_results = get_pesq_scores()\n",
    "score = pesq_results[\"NarrobandSpeech8k.wav\"] [\"NB=8_in_Part1-6.wav\"] \n",
    "print \"score for NB=8: \", score\n",
    "# compare NB=6 with reference audio\n",
    "! ./linux_pesqmain +8000 NarrobandSpeech8k.wav NB=6_in_Part1-6.wav > /dev/null\n",
    "pesq_results = get_pesq_scores()\n",
    "score = pesq_results[\"NarrobandSpeech8k.wav\"] [\"NB=6_in_Part1-6.wav\"] \n",
    "print \"score for NB=6: \", score\n",
    "# compare NB=3 with reference audio\n",
    "! ./linux_pesqmain +8000 NarrobandSpeech8k.wav NB=3_in_Part1-6.wav > /dev/null\n",
    "pesq_results = get_pesq_scores()\n",
    "score = pesq_results[\"NarrobandSpeech8k.wav\"] [\"NB=3_in_Part1-6.wav\"] \n",
    "print \"score for NB=3: \", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.6\n",
    "1.Can you hear any difference between the original 16 bit per sample version and your 8 bit version?\n",
    "   -In 8 bit versin there are unobvious noises that does not appear in 16 bit version.\n",
    "2.Taking ‘Narrobandspeech8k.wav’ as the reference, what are the PESQ scores for (a)your 8 bit per sample version (b)a 4-bit per sample version and (c)any others you tested?\n",
    "   -NB=8:3.648;  NB=6:2.783;  NB=3:1.178\n",
    "3.Compare your own assessments with the PESQ scores obtained for several values of NB.\n",
    "   -When NB is 8(and above) converted audio sounds almost the same as original version; as NB gets lower, converted audio has more blurred sound and audio samples begin to get lost at NB as low as 3. \n",
    "4.Decide what you consider to be a reasonable number of bits (NB) per sample for telephone speech when the sampling rate is 8 kHz with uniform quantisation. Summarise your reasons in one sentence, and note whether your decision is significantly different from the PESQ assessment.\n",
    "   -NB should be 8, as this is convenient for computer to store and it confines wav file size. PESQ suggests that 8-bit version is just perceptable. \n",
    "5.You have heard that land-line telephone calls use 64000 bits/second links. Based on your experiments today, do you consider that 8 bits per sample with uniform quantisation may be acceptable for telephone quality speech sampled at 8 kHz?\n",
    "   -Yes, they sound without much difference.\n",
    "6.Mobile telephony cannot afford 64000 bits/second, and must use considerably less than 16,000 bits/second.  How many bits per sample would be possible using 16000 bits/second with uniform quantisation of speech sampled at 8 kHz?  Based on your experiments, do you believe that reasonable quality speech can be encoded in this way for mobile telephony? \n",
    "   -2bits. No, the quality would be too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot \n",
    "%matplotlib inline\n",
    "rx = numpy.random.rand(200)*2-1\n",
    "rx = numpy.array(sorted(rx)) # random sorted number between -1 and 1\n",
    "ry = numpy.array([0]*200); ru = numpy.array([0]*200)\n",
    "#apply mu-law\n",
    "ry = numpy.sign(rx)*numpy.log(1+255*numpy.absolute(rx))/numpy.log(256)\n",
    "fig, ax0 = pyplot.subplots(1) \n",
    "ax0.plot(rx,ry)   # plot ry against rx\n",
    "ax0.grid(True)\n",
    "ax0.set_xlabel(\"Random\") ; ax0.set_ylabel(\"mu(x)\") \n",
    "# apply mu-law expansion formula\n",
    "ru = numpy.sign(ry)*(numpy.power(256, numpy.absolute(ry))-1)/255\n",
    "fig, ax1 = pyplot.subplots(1)\n",
    "ax1.plot(ry,ru)   # plot ru against ry\n",
    "ax1.grid(True)\n",
    "ax1.set_xlabel(\"mu(x)\") ; ax1.set_ylabel(\"mu_expan(x)\")\n",
    "\n",
    "#operation on audio \n",
    "(Fs_spe, x_spe) = wavfile.read(\"NarrobandSpeech8k.wav\"); \n",
    "utils.Audio(x_spe, rate=Fs_spe,)    # play original speech\n",
    "SM=max(abs(x_spe))         # Get maximum amplitude \n",
    "x_cmp = x_spe/float(SM)    # Scale maximum to 1 (note the float) \n",
    "x_cmp = numpy.array(x_cmp)\n",
    "# apply mu-law\n",
    "x_mu = numpy.sign(x_cmp)*numpy.log(1+255*numpy.absolute(x_cmp))/numpy.log(256)\n",
    "for n in range(3):\n",
    "    x_qut = numpy.round(x_mu * (2**(7-n) - 0.5) - 0.5) # quantise to NB=8\n",
    "        # transmitting……\n",
    "    x_qut = x_qut + 0.5\n",
    "    SM=max(abs(x_qut))         # Get maximum amplitude \n",
    "    x_cmp = x_qut/float(SM)    # Scale maximum to 1 (note the float)\n",
    "    # apply mu-law expansion formula\n",
    "    x_mu_exp = numpy.sign(x_cmp)*(numpy.power(256, numpy.absolute(x_cmp))-1)/255\n",
    "    # quantise to NB=16\n",
    "    quant_y = numpy.round(x_mu_exp * (2**15 - 1))\n",
    "    iquant_y = numpy.int16(quant_y)\n",
    "    print('rendered speech with NB=%d transmission'%(8-n))\n",
    "    wavfile.write(\"NB=%d_in_Part1-7.wav\"%(8-n), Fs_spe, iquant_y);\n",
    "    utils.audio_from_file(\"NB=%d_in_Part1-7.wav\"%(8-n))  # play rendered speech from file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.What do we learn from the mu-law companding and expansion graphs?\n",
    "   -Data valued within samples remained their value.\n",
    "2.Compare mu-Law PCM speech at 64000 bit/s with the result of uniform quantisation at the same bit-rate.  Give PESQ scores and your own assessments for both.\n",
    "   -\n",
    "3.If you have time, compare mu-Law PCM speech with NB=7, 6, etc. with result of uniform quantisation at the same bit-rate (56,000 bit/s, 48,000 bit/s, etc).\n",
    "   -\n",
    "4.scale to+ -1~1 -> mu-law -> uniform quantising to 8 bit -> transmission -> receive -> convert to float -> scale to -1~1 -> mu-law expansion -> quantising to 16 bit "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
